\relax 
\ifx\hyper@anchor\@undefined
\global \let \oldcontentsline\contentsline
\gdef \contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global \let \oldnewlabel\newlabel
\gdef \newlabel#1#2{\newlabelxx{#1}#2}
\gdef \newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\let \contentsline\oldcontentsline
\let \newlabel\oldnewlabel}
\else
\global \let \hyper@last\relax 
\fi

\citation{sutskever2007learning}
\citation{Martens2011}
\citation{bengio2012advances}
\citation{mikolov2011empirical}
\citation{Boulanger-Lewandowski2012}
\citation{bengio2012advances}
\citation{Sutskever2008}
\citation{Boulanger-Lewandowski2012}
\citation{boulangerphone}
\citation{Boulanger-Lewandowski2012}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}}
\newlabel{intro}{{1}{1}{Introduction\relax }{section.1}{}}
\citation{theis2011all}
\citation{Uria2013}
\citation{bishop1994mixture}
\citation{Boulanger-Lewandowski2012}
\citation{rumelhart1985learning}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Graphical structure of the generative RNN. Broken arrows indicate optional connections for temporal smoothing.}}{2}{figure.1}}
\newlabel{fig:rnn}{{1}{2}{Recurrent Neural Networks as generative models\relax }{figure.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Recurrent Neural Networks as generative models}{2}{section.2}}
\newlabel{RNN}{{2}{2}{Recurrent Neural Networks as generative models\relax }{section.2}{}}
\newlabel{rnn-hidden}{{1}{2}{Recurrent Neural Networks as generative models\relax }{equation.1}{}}
\citation{AISTATS2011_Bengio11}
\@writefile{toc}{\contentsline {section}{\numberline {3}The RNADE}{3}{section.3}}
\newlabel{RNADE}{{3}{3}{The RNADE\relax }{section.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}RNN-RNADE}{3}{section.4}}
\newlabel{RNN-RNADE}{{4}{3}{RNN-RNADE\relax }{section.4}{}}
\citation{Uria2013}
\citation{Uria2013}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Graphical structure of the RNN-RNADE. The hidden state of the RNN at time $t$ predicts the parameters of the RNADE at $t+1$. }}{4}{figure.2}}
\newlabel{fig:rnn-rnade}{{2}{4}{RNN-RNADE\relax }{figure.2}{}}
\newlabel{one}{{2}{4}{RNN-RNADE\relax }{equation.2}{}}
\newlabel{two}{{3}{4}{RNN-RNADE\relax }{equation.3}{}}
\newlabel{three}{{4}{4}{RNN-RNADE\relax }{equation.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Learning in the RNN-RNADE}{4}{subsection.4.1}}
\newlabel{cost}{{5}{4}{Learning in the RNN-RNADE\relax }{equation.5}{}}
\citation{bergstra+al:2010-scipy}
\citation{Martens2011}
\citation{Sutskever2008}
\citation{Boulanger-Lewandowski2012}
\citation{Sutskever2008}
\citation{Boulanger-Lewandowski2012}
\newlabel{grad-hidden}{{9}{5}{Learning in the RNN-RNADE\relax }{equation.9}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Experiments}{5}{section.5}}
\newlabel{Experiments}{{5}{5}{Experiments\relax }{section.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}2d stochastic trajectory}{5}{subsection.5.1}}
\citation{Sutskever2008}
\citation{Boulanger-Lewandowski2012}
\bibdata{bibliography}
\bibcite{AISTATS2011_Bengio11}{1}
\bibcite{bengio2012advances}{2}
\bibcite{bergstra+al:2010-scipy}{3}
\bibcite{bishop1994mixture}{4}
\bibcite{Boulanger-Lewandowski2012}{5}
\bibcite{boulangerphone}{6}
\bibcite{Martens2011}{7}
\bibcite{mikolov2011empirical}{8}
\bibcite{rumelhart1985learning}{9}
\bibcite{sutskever2007learning}{10}
\bibcite{Sutskever2008}{11}
\bibcite{theis2011all}{12}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Motion capture data}{6}{subsection.5.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Videos of bouncing balls}{6}{subsection.5.3}}
\bibcite{Uria2013}{13}
\bibstyle{plain}
